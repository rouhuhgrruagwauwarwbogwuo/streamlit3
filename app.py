import streamlit as st
import cv2
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import load_model
from mtcnn import MTCNN
import matplotlib.pyplot as plt

# åŠ è¼‰ ResNet50 æ¨¡å‹
resnet_model = ResNet50(weights='imagenet')

# å‡è¨­é€™æ˜¯ä½ çš„è‡ªè¨‚ CNN æ¨¡å‹
custom_model = load_model('custom_cnn_model.h5')

# ğŸ”¹ åµæ¸¬è‡‰éƒ¨
def detect_faces(image):
    detector = MTCNN()
    faces = detector.detect_faces(image)
    return faces

# ğŸ”¹ é«˜é€šæ¿¾æ³¢è™•ç†
def apply_highpass_filter(image):
    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    highpass = cv2.Laplacian(gray_img, cv2.CV_64F)
    return highpass

# ğŸ”¹ é »åŸŸåˆ†æ (FFT)
def apply_fft(image):
    f = np.fft.fft2(image)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = np.log(np.abs(fshift) + 1)
    return magnitude_spectrum

# ğŸ”¹ é è™•ç†åœ–ç‰‡ï¼Œæº–å‚™ ResNet50 å’Œè‡ªè¨‚ CNN æ¨¡å‹
def preprocess_for_both_models(image_path):
    img = image.load_img(image_path, target_size=(256, 256))
    img_array = image.img_to_array(img)
    
    # ResNet50 é ˆä½¿ç”¨ preprocess_input
    resnet_input = preprocess_input(np.expand_dims(img_array, axis=0))
    
    # è‡ªè¨‚ CNN éœ€è¦æ¨™æº–åŒ–
    custom_input = np.expand_dims(img_array / 255.0, axis=0)
    
    return resnet_input, custom_input

# ğŸ”¹ æ™‚é–“ä¸ä¸€è‡´æ€§æª¢æ¸¬ (é€å¹€è™•ç†å½±ç‰‡)
def process_video_for_inconsistencies(video_path):
    cap = cv2.VideoCapture(video_path)
    prev_frame = None
    
    while(cap.isOpened()):
        ret, frame = cap.read()
        if not ret:
            break
        
        faces = detect_faces(frame)
        
        if prev_frame is not None:
            # è¨ˆç®—èˆ‡å‰ä¸€å¹€çš„å·®ç•°
            frame_diff = cv2.absdiff(prev_frame, frame)
            gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray_diff, 30, 255, cv2.THRESH_BINARY)
            cv2.imshow("Frame Difference", thresh)
        
        prev_frame = frame
        
        cv2.imshow('Video Frame', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

# ğŸ”¹ ä¸»ç¨‹åºè™•ç†åœ–ç‰‡
def process_image(image_path):
    # é è™•ç†åœ–åƒ
    resnet_input, custom_input = preprocess_for_both_models(image_path)

    # ä½¿ç”¨ ResNet50 é€²è¡Œé æ¸¬
    resnet_pred = resnet_model.predict(resnet_input)
    resnet_pred_class = np.argmax(resnet_pred, axis=1)

    # ä½¿ç”¨è‡ªè¨‚ CNN æ¨¡å‹é€²è¡Œé æ¸¬
    custom_pred = custom_model.predict(custom_input)
    custom_pred_class = np.argmax(custom_pred, axis=1)

    # é¡¯ç¤ºçµæœ
    st.image(image_path, use_column_width=True)
    st.write(f"ResNet50 é æ¸¬çµæœ: {resnet_pred_class}")
    st.write(f"è‡ªè¨‚ CNN é æ¸¬çµæœ: {custom_pred_class}")

    # é¡¯ç¤ºåœ–ç‰‡çš„é«˜é€šæ¿¾æ³¢çµæœ
    image = cv2.imread(image_path)
    highpass_image = apply_highpass_filter(image)
    st.image(highpass_image, caption='é«˜é€šæ¿¾æ³¢è™•ç†éçš„åœ–ç‰‡', use_column_width=True)

    # é¡¯ç¤ºé »åŸŸåˆ†æåœ–
    magnitude_spectrum = apply_fft(image)
    st.image(magnitude_spectrum, caption='é »åŸŸåˆ†æçµæœ', use_column_width=True)

# ğŸ”¹ ä¸»ç¨‹åºè™•ç†å½±ç‰‡
def process_video(video_path):
    st.write("å½±ç‰‡è™•ç†ä¸­...")
    process_video_for_inconsistencies(video_path)

# Streamlit UI
st.title("Deepfake åµæ¸¬")

st.write("è«‹ä¸Šå‚³åœ–ç‰‡æˆ–å½±ç‰‡é€²è¡Œåµæ¸¬ï¼š")

uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡æˆ–å½±ç‰‡", type=["jpg", "png", "mp4", "mov"])

if uploaded_file is not None:
    file_extension = uploaded_file.name.split('.')[-1].lower()
    
    if file_extension in ['jpg', 'png']:
        # å„²å­˜åœ–ç‰‡ä¸¦é¡¯ç¤ºè™•ç†çµæœ
        image_path = f"temp_image.{file_extension}"
        with open(image_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        process_image(image_path)
    
    elif file_extension in ['mp4', 'mov']:
        # å„²å­˜å½±ç‰‡ä¸¦é¡¯ç¤ºè™•ç†çµæœ
        video_path = f"temp_video.{file_extension}"
        with open(video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        process_video(video_path)
