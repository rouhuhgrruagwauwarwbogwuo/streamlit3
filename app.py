import streamlit as st
import numpy as np
import os
import requests
from PIL import Image
import cv2
import tempfile
from keras.applications import ResNet50, EfficientNetB0, Xception
from keras.models import Sequential
from keras.layers import Dense
from keras.applications.resnet50 import preprocess_input as preprocess_resnet
from keras.applications.efficientnet import preprocess_input as preprocess_efficientnet
from keras.applications.xception import preprocess_input as preprocess_xception
from mtcnn import MTCNN
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# ä¸‹è¼‰æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_filename = "deepfake_cnn_model.h5"
    if not os.path.exists(model_filename):
        response = requests.get(model_url)
        if response.status_code == 200:
            with open(model_filename, "wb") as f:
                f.write(response.content)
            print("æ¨¡å‹ä¸‹è¼‰æˆåŠŸï¼")
        else:
            print(f"ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None
    return model_filename

# è¼‰å…¥æ¨¡å‹
def load_models():
    try:
        resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
        efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
        xception_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))

        # è‡ªè¨‚åˆ†é¡å™¨
        resnet_classifier = Sequential([resnet_model, Dense(1, activation='sigmoid')])
        efficientnet_classifier = Sequential([efficientnet_model, Dense(1, activation='sigmoid')])
        xception_classifier = Sequential([xception_model, Dense(1, activation='sigmoid')])

        return {
            'ResNet50': resnet_classifier,
            'EfficientNet': efficientnet_classifier,
            'Xception': xception_classifier
        }
    except Exception as e:
        print(f"è¼‰å…¥æ¨¡å‹æ™‚å‡ºéŒ¯: {e}")
        return None

# MTCNN åˆå§‹åŒ–
detector = MTCNN()

# æå–äººè‡‰
def extract_face(pil_img):
    img_array = np.array(pil_img)
    faces = detector.detect_faces(img_array)
    if len(faces) > 0:
        x, y, w, h = faces[0]['box']
        face = img_array[y:y+h, x:x+w]
        return Image.fromarray(face)
    return None

# åœ–åƒé è™•ç†
def preprocess_image(img, model_name):
    img_resized = img.resize((224, 224))  # å°æ‰€æœ‰æ¨¡å‹é€²è¡Œ 224x224 é‡è¨­
    img_array = np.array(img_resized).astype(np.float32) / 255.0  # æ¨™æº–åŒ– RGB åœ–åƒ

    if model_name == 'ResNet50':
        return preprocess_resnet(img_array)
    elif model_name == 'EfficientNet':
        return preprocess_efficientnet(img_array)
    elif model_name == 'Xception':
        img_resized = img.resize((299, 299))  # Xception è¦æ±‚ 299x299 å¤§å°
        img_array = np.array(img_resized).astype(np.float32) / 255.0
        return preprocess_xception(img_array)
    return img_array

# æ¨¡å‹é æ¸¬
def predict_model(models, img):
    predictions = []
    for model_name, model in models.items():
        preprocessed_img = preprocess_image(img, model_name)
        prediction = model.predict(np.expand_dims(preprocessed_img, axis=0))  # å¢åŠ æ‰¹æ¬¡ç¶­åº¦
        predictions.append(prediction[0][0])  # æ‰å¹³åŒ–é æ¸¬çµæœ
    return predictions

# å †ç–Šé æ¸¬ï¼ˆé›†æˆå­¸ç¿’ï¼‰
def stacking_predict(models, img):
    if not models:  # å¦‚æœæ¨¡å‹å­—å…¸ç‚ºç©ºï¼Œè¿”å›éŒ¯èª¤è¨Šæ¯
        return "æ¨¡å‹åŠ è¼‰å¤±æ•—"
    
    predictions = predict_model(models, img)
    
    # ç¢ºä¿é æ¸¬çµæœæ˜¯ 2D æ•¸çµ„ï¼Œä¸¦æ ¹æ“šéœ€è¦é‡å¡‘
    stacked_predictions = np.array(predictions).reshape(1, -1)  # (1, n_models)
    print("å †ç–Šé æ¸¬:", stacked_predictions)  # èª¿è©¦è¼¸å‡º

    # å‰µå»ºæ¨™ç±¤ï¼ˆDeepfake ç‚º 1ï¼ŒReal ç‚º 0ï¼‰
    labels = [1 if p > 0.5 else 0 for p in predictions]
    print("æ¨™ç±¤:", labels)  # èª¿è©¦è¼¸å‡º
    
    labels = np.array(labels).reshape(-1, 1)  # ç¢ºä¿æ¨™ç±¤æ˜¯ 2D æ•¸çµ„ (n_samples, 1)
    print("é‡å¡‘å¾Œæ¨™ç±¤:", labels)  # èª¿è©¦è¼¸å‡º

    try:
        # åˆ†å‰²è³‡æ–™ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
        X_train, X_test, y_train, y_test = train_test_split(stacked_predictions, labels, test_size=0.2, random_state=42)
        
        logistic_model = LogisticRegression()
        logistic_model.fit(X_train, y_train.ravel())  # æŠŠ y_train å£“å¹³æˆä¸€ç¶­

        # åœ¨æ¸¬è©¦é›†ä¸Šé€²è¡Œé æ¸¬
        final_prediction = logistic_model.predict(X_test)[0]
        print("æœ€çµ‚é æ¸¬:", final_prediction)  # èª¿è©¦è¼¸å‡º
        return "Deepfake" if final_prediction == 1 else "Real"
    except ValueError as e:
        print(f"è¨“ç·´é‚è¼¯å›æ­¸æ¨¡å‹æ™‚å‡ºéŒ¯: {e}")
        return "æ¨¡å‹è¨“ç·´å¤±æ•—"

# é¡¯ç¤ºé æ¸¬çµæœ
def show_prediction(img, models):
    label = stacking_predict(models, img)
    st.image(img, caption="è¼¸å…¥åœ–åƒ", use_container_width=True)
    st.subheader(f"é›†æˆæ¨¡å‹é æ¸¬çµæœ: **{label}**")

# Streamlit UI
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–åƒåµæ¸¬å™¨")

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–åƒåµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

# åœ–åƒåµæ¸¬
with tab1:
    st.header("ä¸Šå‚³åœ–åƒé€²è¡Œ Deepfake åµæ¸¬")
    uploaded_image = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–åƒ", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–åƒ", use_container_width=True)

        face_img = extract_face(pil_img)
        if face_img:
            st.image(face_img, caption="åµæ¸¬åˆ°çš„äººè‡‰", width=300)
            models = load_models()
            show_prediction(face_img, models)
        else:
            st.info("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°äººè‡‰ï¼Œä½¿ç”¨æ•´å¼µåœ–é€²è¡Œé æ¸¬")
            models = load_models()
            show_prediction(pil_img, models)

# å½±ç‰‡åµæ¸¬ï¼ˆåªè™•ç†å‰å¹¾å¹€ï¼‰
with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆè™•ç†å‰å¹¾å¹€ï¼‰")
    uploaded_video = st.file_uploader("é¸æ“‡ä¸€æ®µå½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        import cv2
        st.info("ğŸ¬ æ­£åœ¨æå–å¹€ä¸¦åˆ†æ...")
        cap = cv2.VideoCapture(video_path)
        frame_idx = 0
        shown = False

        while cap.isOpened() and not shown:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % 10 == 0:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_frame = Image.fromarray(rgb)
                face_img = extract_face(pil_frame)
                if face_img:
                    st.image(face_img, caption=f"ç¬¬ {frame_idx} å¹€ åµæ¸¬åˆ°çš„äººè‡‰", width=300)
                    models = load_models()
                    show_prediction(face_img, models)
                    shown = True
            frame_idx += 1

        cap.release()
