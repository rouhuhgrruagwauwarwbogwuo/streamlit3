import streamlit as st
import numpy as np
import cv2
import tempfile
import requests
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

# ==== è¨­ç½®é é¢é…ç½® ====
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")

# ğŸ”¹ ä¸‹è¼‰æ¨¡å‹ï¼ˆåªæœƒä¸‹è¼‰ä¸€æ¬¡ï¼‰
@st.cache_resource
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_path = "deepfake_cnn_model.h5"
    if not os.path.exists(model_path):
        with st.spinner("ä¸‹è¼‰æ¨¡å‹ä¸­..."):
            r = requests.get(model_url)
            with open(model_path, "wb") as f:
                f.write(r.content)
    return load_model(model_path)

# ğŸ”¹ è¼‰å…¥ ResNet50 æ¨¡å‹
resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))
resnet_classifier = Sequential([
    resnet_model,
    Dense(1, activation='sigmoid')  # 1 å€‹è¼¸å‡ºç¯€é»ï¼ˆ0: çœŸå¯¦, 1: å‡ï¼‰
])
resnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ğŸ”¹ è¼‰å…¥è‡ªè¨‚ CNN æ¨¡å‹
custom_model = download_model()

# ğŸ”¹ å»å™ª + å…‰ç·šæ¨™æº–åŒ–çš„é è™•ç†å‡½æ•¸
def preprocess_image(image_path, target_size=(256, 256)):
    try:
        img = image.load_img(image_path, target_size=target_size)
        img_array = image.img_to_array(img).astype('uint8')

        # è½‰æ›æˆç°éš
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        img_gray = clahe.apply(img_gray)
        
        # è½‰å› 3 é€šé“
        img_array = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)
        
        # æ¨™æº–åŒ–å½±åƒ (0~1)
        img_array = img_array / 255.0
        
        return np.expand_dims(img_array, axis=0)  # å¢åŠ  batch ç¶­åº¦
    
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None

# ğŸ”¹ é è™•ç†åœ–ç‰‡ï¼Œç¢ºä¿ ResNet å’Œ è‡ªè¨‚ CNN éƒ½èƒ½è™•ç†
def preprocess_for_both_models(image_path):
    img = image.load_img(image_path, target_size=(256, 256))  # èª¿æ•´å¤§å°
    img_array = image.img_to_array(img)
    
    # ResNet50 éœ€è¦ç‰¹åˆ¥çš„ preprocess_input
    resnet_input = preprocess_input(np.expand_dims(img_array, axis=0))
    
    # è‡ªè¨‚ CNN åªéœ€è¦æ­£è¦åŒ– (0~1)
    custom_input = np.expand_dims(img_array / 255.0, axis=0)
    
    return resnet_input, custom_input

# ğŸ”¹ é€²è¡Œé æ¸¬
def predict_with_both_models(image_path):
    try:
        resnet_input, custom_input = preprocess_for_both_models(image_path)
        
        # æª¢æŸ¥é è™•ç†å¾Œçš„è¼¸å…¥å½¢ç‹€
        print(f"ResNet input shape: {resnet_input.shape}")
        
        # ResNet50 é æ¸¬
        resnet_prediction = resnet_classifier.predict(resnet_input)
        if resnet_prediction.ndim > 1:
            resnet_prediction = resnet_prediction[0][0]  # è‹¥è¿”å›å¤šç¶­ï¼Œå–å‡ºæ‰€éœ€çš„éƒ¨åˆ†
        resnet_label = "Deepfake" if resnet_prediction > 0.5 else "Real"
        
        # è‡ªè¨‚ CNN æ¨¡å‹é æ¸¬
        custom_prediction = custom_model.predict(custom_input)[0][0]
        custom_label = "Deepfake" if custom_prediction > 0.5 else "Real"
        
        return resnet_label, resnet_prediction, custom_label, custom_prediction
    
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None, None, None, None

# ğŸ”¹ é¡¯ç¤ºåœ–ç‰‡å’Œé æ¸¬çµæœ
def show_prediction(image_path):
    resnet_label, resnet_confidence, custom_label, custom_confidence = predict_with_both_models(image_path)
    
    # é¡¯ç¤ºåœ–ç‰‡
    img = image.load_img(image_path, target_size=(256, 256))
    st.image(img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)
    
    # é¡¯ç¤ºé æ¸¬çµæœ
    if resnet_label and custom_label:
        st.subheader(f"ResNet50: {resnet_label} ({resnet_confidence:.2%} ä¿¡å¿ƒåˆ†æ•¸)")
        st.subheader(f"Custom CNN: {custom_label} ({custom_confidence:.2%} ä¿¡å¿ƒåˆ†æ•¸)")

# ==== Streamlit App ä¸»é«” ====
st.title("ğŸ§  Deepfake åœ–ç‰‡åµæ¸¬å™¨")

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–ç‰‡åµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

# ---------- åœ–ç‰‡ ----------
with tab1:
    st.header("åœ–ç‰‡åµæ¸¬")
    uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        image_path = uploaded_image.name
        with open(image_path, "wb") as f:
            f.write(uploaded_image.getbuffer())
        
        show_prediction(image_path)

# ---------- å½±ç‰‡ ----------
with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆæ¯ 10 å¹€æŠ½åœ–ï¼‰")
    uploaded_video = st.file_uploader("ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        st.info("ğŸ¬ æ“·å–å½±ç‰‡å¹€èˆ‡é€²è¡Œé æ¸¬ä¸­...")

        frames = extract_frames(video_path, interval=10)
        results = predict_frames(resnet_classifier, frames)

        for idx, frame, label, confidence in results:
            st.image(frame, caption=f"ç¬¬ {idx} å¹€ - {label} ({confidence:.2%})", use_container_width=True)
