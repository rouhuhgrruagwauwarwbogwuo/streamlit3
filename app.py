import streamlit as st
import numpy as np
import os
import requests
from PIL import Image
import cv2
import tempfile
from keras.applications import ResNet50, EfficientNetB0, Xception
from keras.models import Sequential
from keras.layers import Dense
from keras.applications.resnet50 import preprocess_input as preprocess_resnet
from keras.applications.efficientnet import preprocess_input as preprocess_efficientnet
from keras.applications.xception import preprocess_input as preprocess_xception
from mtcnn import MTCNN
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# â¬‡ï¸ ä¸‹è¼‰æ¨¡å‹ï¼ˆå¦‚æœé‚„æ²’ä¸‹è¼‰ï¼‰
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_filename = "deepfake_cnn_model.h5"
    if not os.path.exists(model_filename):
        response = requests.get(model_url)
        if response.status_code == 200:
            with open(model_filename, "wb") as f:
                f.write(response.content)
            print("æ¨¡å‹ä¸‹è¼‰æˆåŠŸï¼")
        else:
            print(f"ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")
            return None
    return model_filename

# âœ… è¼‰å…¥ ResNet50ã€EfficientNet å’Œ Xception æ¨¡å‹
def load_models():
    try:
        resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
        efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
        xception_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))

        # è‡ªå®šç¾©åˆ†é¡å™¨
        resnet_classifier = Sequential([resnet_model, Dense(1, activation='sigmoid')])
        efficientnet_classifier = Sequential([efficientnet_model, Dense(1, activation='sigmoid')])
        xception_classifier = Sequential([xception_model, Dense(1, activation='sigmoid')])

        return {
            'ResNet50': resnet_classifier,
            'EfficientNet': efficientnet_classifier,
            'Xception': xception_classifier
        }
    except Exception as e:
        print(f"è¼‰å…¥æ¨¡å‹éŒ¯èª¤ï¼š{e}")
        return None

# âœ… MTCNN åˆå§‹åŒ–
detector = MTCNN()

# âœ… æ“·å–äººè‡‰
def extract_face(pil_img):
    img_array = np.array(pil_img)
    faces = detector.detect_faces(img_array)
    if len(faces) > 0:
        x, y, w, h = faces[0]['box']
        face = img_array[y:y+h, x:x+w]
        return Image.fromarray(face)
    return None

# âœ… åœ–ç‰‡é è™•ç†
def preprocess_image(img, model_name):
    img_array = np.array(img)
    
    # èª¿æ•´åœ–åƒå¤§å°
    img_resized = img.resize((224, 224))  # æ‰€æœ‰æ¨¡å‹éƒ½éœ€è¦ 224x224 å¤§å°çš„åœ–ç‰‡
    img_array = np.array(img_resized)

    img_array = img_array.astype(np.float32) / 255.0  # è™•ç† RGB åœ–åƒ
    
    if model_name == 'ResNet50':
        return preprocess_resnet(img_array)
    elif model_name == 'EfficientNet':
        return preprocess_efficientnet(img_array)
    elif model_name == 'Xception':
        return preprocess_xception(img_array)
    return img_array

# âœ… é æ¸¬
def predict_model(models, img):
    predictions = []
    for model_name, model in models.items():
        preprocessed_img = preprocess_image(img, model_name)
        prediction = model.predict(np.expand_dims(preprocessed_img, axis=0))[0][0]
        predictions.append(prediction)
    return predictions

# âœ… Stacking é æ¸¬ï¼ˆé›†æˆå­¸ç¿’ï¼‰
def stacking_predict(models, img):
    predictions = predict_model(models, img)
    
    # ç¢ºä¿ predictions æ˜¯ä¸€ç¶­é™£åˆ—ï¼Œä¸¦è½‰æ›ç‚º 2D é™£åˆ—ï¼ˆæ¯å€‹æ¨¡å‹ä¸€è¡Œï¼‰
    stacked_predictions = np.array(predictions).reshape(-1, 1)

    # è¨­å®šæ¯å€‹é æ¸¬çµæœçš„æ¨™ç±¤ï¼ˆ1è¡¨ç¤ºDeepfakeï¼Œ0è¡¨ç¤ºRealï¼‰
    labels = [1 if p > 0.5 else 0 for p in predictions]
    
    # ä½¿ç”¨é‚è¼¯å›æ­¸é€²è¡Œé æ¸¬èåˆ
    logistic_model = LogisticRegression()
    logistic_model.fit(stacked_predictions, labels)

    # è¼¸å‡ºæœ€çµ‚é æ¸¬
    final_prediction = logistic_model.predict(stacked_predictions)[0]
    return "Deepfake" if final_prediction == 1 else "Real"

# âœ… é¡¯ç¤ºé æ¸¬
def show_prediction(img, models):
    label = stacking_predict(models, img)
    st.image(img, caption="è¼¸å…¥åœ–ç‰‡", use_container_width=True)
    st.subheader(f"é›†æˆæ¨¡å‹åˆ¤æ–·ï¼š**{label}**")

# âœ… Streamlit UI
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–ç‰‡åµæ¸¬å™¨")

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–ç‰‡åµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

# âœ… åœ–ç‰‡åµæ¸¬
with tab1:
    st.header("ä¸Šå‚³åœ–ç‰‡é€²è¡Œ Deepfake åµæ¸¬")
    uploaded_image = st.file_uploader("è«‹é¸æ“‡åœ–ç‰‡", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)

        face_img = extract_face(pil_img)
        if face_img:
            st.image(face_img, caption="åµæ¸¬åˆ°äººè‡‰", width=300)
            models = load_models()
            show_prediction(face_img, models)
        else:
            st.info("âš ï¸ æœªåµæ¸¬åˆ°äººè‡‰ï¼Œå°‡ä½¿ç”¨æ•´å¼µåœ–ç‰‡é€²è¡Œé æ¸¬")
            models = load_models()
            show_prediction(pil_img, models)

# âœ… å½±ç‰‡åµæ¸¬ï¼ˆåƒ…æ“·å–å‰å¹¾å¹€ï¼‰
with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆåƒ…æ“·å–å‰å¹¾å¹€é€²è¡Œåˆ¤æ–·ï¼‰")
    uploaded_video = st.file_uploader("è«‹ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        import cv2
        st.info("ğŸ¬ æ“·å–å¹€èˆ‡åˆ†æä¸­...")
        cap = cv2.VideoCapture(video_path)
        frame_idx = 0
        shown = False

        while cap.isOpened() and not shown:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % 10 == 0:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_frame = Image.fromarray(rgb)
                face_img = extract_face(pil_frame)
                if face_img:
                    st.image(face_img, caption=f"ç¬¬ {frame_idx} å¹€åµæ¸¬åˆ°äººè‡‰", width=300)
                    models = load_models()
                    show_prediction(face_img, models)
                    shown = True
            frame_idx += 1

        cap.release()
