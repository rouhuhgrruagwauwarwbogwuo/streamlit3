import cv2
import numpy as np
from PIL import Image
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
import random

# ğŸ”¹ å¢åŠ åœ–ç‰‡å¢å¼·èˆ‡è™•ç†
def preprocess_for_both_models(img):
    # 1ï¸âƒ£ **é«˜æ¸…åœ–è™•ç†ï¼šLANCZOS ç¸®åœ–**
    img = img.resize((256, 256), Image.Resampling.LANCZOS)

    # 2ï¸âƒ£ **ResNet50 å¿…é ˆ 224x224**
    img = center_crop(img, (224, 224))

    img_array = np.array(img)  # è½‰ç‚º numpy array

    # 3ï¸âƒ£ **å¯é¸ï¼šå° ResNet50 åš Gaussian Blur**
    apply_blur = True  # ğŸš€ é€™è£¡å¯ä»¥é–‹é—œ
    if apply_blur:
        img_array = cv2.GaussianBlur(img_array, (3, 3), 0)

    # 4ï¸âƒ£ **é€²è¡Œé¡è‰²ç©ºé–“è½‰æ›ï¼šè½‰æ›åˆ° YCbCr æˆ– Lab ç©ºé–“**
    apply_color_space_conversion = True
    if apply_color_space_conversion:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)  # è½‰æ›ç‚º YCbCr è‰²å½©ç©ºé–“
        # img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2Lab)  # å¯é¸ï¼šè½‰æ›ç‚º Lab è‰²å½©ç©ºé–“

    # 5ï¸âƒ£ **æ‡‰ç”¨ CLAHEï¼ˆå°æ¯”åº¦å—é™è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡åŒ–ï¼‰**
    apply_clahe = True
    if apply_clahe:
        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2Lab)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        cl = clahe.apply(l)
        limg = cv2.merge((cl, a, b))
        img_array = cv2.cvtColor(limg, cv2.COLOR_Lab2RGB)

    # 6ï¸âƒ£ **éš¨æ©Ÿæ—‹è½‰æˆ–ç¸®æ”¾åœ–ç‰‡ï¼ˆæ•¸æ“šå¢å¼·ï¼‰**
    random_flip = random.choice([True, False])
    if random_flip:
        img_array = np.fliplr(img_array)  # éš¨æ©Ÿå·¦å³ç¿»è½‰

    random_rotate = random.choice([True, False])
    if random_rotate:
        angle = random.randint(-10, 10)
        height, width = img_array.shape[:2]
        matrix = cv2.getRotationMatrix2D((width // 2, height // 2), angle, 1)
        img_array = cv2.warpAffine(img_array, matrix, (width, height))

    # 7ï¸âƒ£ **ResNet50 ç‰¹å®šé è™•ç†**
    resnet_input = preprocess_input(np.expand_dims(img_array, axis=0))

    # 8ï¸âƒ£ **è‡ªè¨‚ CNN æ­£è¦åŒ– (0~1)**
    custom_input = np.expand_dims(img_array / 255.0, axis=0)

    return resnet_input, custom_input

# ğŸ”¹ ä¸­å¿ƒè£å‰ªå‡½æ•¸ï¼šå°åœ–ç‰‡é€²è¡Œè£å‰ªï¼Œä½¿å…¶ç¬¦åˆç›®æ¨™å¤§å°
def center_crop(img, target_size):
    width, height = img.size
    target_width, target_height = target_size

    left = (width - target_width) // 2
    top = (height - target_height) // 2
    right = (width + target_width) // 2
    bottom = (height + target_height) // 2

    img = img.crop((left, top, right, bottom))
    return img

# ğŸ”¹ æ¸¬è©¦ç”¨çš„åœ–ç‰‡è™•ç†ç¤ºç¯„
if __name__ == "__main__":
    # è¼‰å…¥åœ–ç‰‡
    img_path = "your_image_path.jpg"  # è«‹æ›¿æ›ç‚ºåœ–ç‰‡è·¯å¾‘
    img = Image.open(img_path)

    # é è™•ç†åœ–ç‰‡ï¼Œé©ç”¨æ–¼ ResNet50 å’Œè‡ªè¨‚ CNN
    resnet_input, custom_input = preprocess_for_both_models(img)

    # è¼¸å‡ºè™•ç†å¾Œçš„åœ–ç‰‡å°ºå¯¸èˆ‡æ ¼å¼
    print(f"ResNet50 Input Shape: {resnet_input.shape}")
    print(f"Custom CNN Input Shape: {custom_input.shape}")
