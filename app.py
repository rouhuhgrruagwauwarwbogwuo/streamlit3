import streamlit as st
import numpy as np
import os
import requests
from PIL import Image
import cv2
import tempfile
import pywt
from keras.applications import ResNet50, EfficientNetB0, Xception
from keras.models import Sequential
from keras.layers import Dense
from keras.applications.resnet50 import preprocess_input as preprocess_resnet
from keras.applications.efficientnet import preprocess_input as preprocess_efficientnet
from keras.applications.xception import preprocess_input as preprocess_xception
from mtcnn import MTCNN
import matplotlib.pyplot as plt
from scipy.fftpack import fft, ifft

# åˆå§‹åŒ– MTCNN
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–åƒåµæ¸¬å™¨")
detector = MTCNN()

# è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_models():
    resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
    efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
    xception_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(299, 299, 3))

    resnet_classifier = Sequential([resnet_model, Dense(1, activation='sigmoid')])
    efficientnet_classifier = Sequential([efficientnet_model, Dense(1, activation='sigmoid')])
    xception_classifier = Sequential([xception_model, Dense(1, activation='sigmoid')])

    return {
        'ResNet50': resnet_classifier,
        'EfficientNet': efficientnet_classifier,
        'Xception': xception_classifier
    }

# æå–äººè‡‰
@st.cache_data(show_spinner=False)
def extract_face(pil_img):
    img_array = np.array(pil_img)
    faces = detector.detect_faces(img_array)
    if faces:
        x, y, w, h = faces[0]['box']
        face = img_array[y:y+h, x:x+w]
        return Image.fromarray(face)
    return None

# é è™•ç†å„ªåŒ–ï¼šCLAHE + éŠ³åŒ–
def apply_clahe_sharpen(img):
    img_np = np.array(img)
    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    lab = cv2.merge((cl, a, b))
    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

    # éŠ³åŒ–
    blurred = cv2.GaussianBlur(img_clahe, (0, 0), 3)
    sharpened = cv2.addWeighted(img_clahe, 1.5, blurred, -0.5, 0)
    return Image.fromarray(sharpened)

# é«˜é »æ¿¾æ³¢è™•ç†
def high_pass_filter(img):
    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    rows, cols = img_gray.shape
    dft = cv2.dft(np.float32(img_gray), flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    
    # è¨­å®šé«˜é »æ¿¾æ³¢å™¨
    center = (rows // 2, cols // 2)
    radius = 30
    mask = np.ones((rows, cols, 2), np.uint8)
    cv2.circle(mask, center, radius, (0, 0, 0), -1)
    
    # æ‡‰ç”¨æ¿¾æ³¢
    fshift = dft_shift * mask
    f_ishift = np.fft.ifftshift(fshift)
    img_back = cv2.idft(f_ishift)
    img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])
    return np.uint8(np.abs(img_back))

# å°æ³¢è®Šæ›ï¼ˆWavelet Transformï¼‰
def wavelet_transform(img):
    img_np = np.array(img)
    coeffs = pywt.dwt2(img_np, 'bior1.3')  # é€™æ˜¯å¸¸ç”¨çš„å°æ³¢è®Šæ›
    LL, (LH, HL, HH) = coeffs
    # è¿”å›å°æ³¢è®Šæ›çš„å››å€‹éƒ¨åˆ†
    return LL, LH, HL, HH

# é è™•ç†åœ–åƒ
def preprocess_image(img, model_name):
    img = apply_clahe_sharpen(img)  # é è™•ç†å„ªåŒ–åŠ å…¥æ­¤è¡Œ

    if model_name == 'Xception':
        img = img.resize((299, 299))
        img_array = np.array(img).astype(np.float32)
        return preprocess_xception(img_array)
    else:
        img = img.resize((224, 224))
        img_array = np.array(img).astype(np.float32)
        if model_name == 'ResNet50':
            return preprocess_resnet(img_array)
        elif model_name == 'EfficientNet':
            return preprocess_efficientnet(img_array)
    return img_array

# å–®æ¨¡å‹é æ¸¬
def predict_model(models, img):
    predictions = []
    for name, model in models.items():
        input_data = preprocess_image(img, name)
        prediction = model.predict(np.expand_dims(input_data, axis=0), verbose=0)
        predictions.append(prediction[0][0])
    return predictions

# é›†æˆé æ¸¬ï¼ˆç°¡å–®å¹³å‡ï¼‰
def stacking_predict(models, img):
    preds = predict_model(models, img)
    avg = np.mean(preds)
    return "Deepfake" if avg > 0.5 else "Real", avg

# é¡¯ç¤ºé æ¸¬çµæœ
def show_prediction(img, models):
    label, confidence = stacking_predict(models, img)
    st.image(img, caption="è¼¸å…¥åœ–åƒ", use_container_width=True)
    st.subheader(f"é æ¸¬çµæœï¼š**{label}**")
    st.markdown(f"ä¿¡å¿ƒåˆ†æ•¸ï¼š**{confidence:.2f}**")

    # é¡¯ç¤ºä¿¡å¿ƒåˆ†æ•¸æ¢
    fig, ax = plt.subplots(figsize=(6, 1))
    ax.barh([0], confidence, color='green' if label == "Real" else 'red')
    ax.set_xlim(0, 1)
    ax.set_yticks([])
    ax.set_xlabel('ä¿¡å¿ƒåˆ†æ•¸')
    st.pyplot(fig)

# UI Tab
models = load_models()
tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–åƒåµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

with tab1:
    st.header("ä¸Šå‚³åœ–åƒé€²è¡Œ Deepfake åµæ¸¬")
    uploaded_image = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–åƒ", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–åƒ", use_container_width=True)

        # é«˜é »æ¿¾æ³¢è™•ç†
        filtered_img = high_pass_filter(np.array(pil_img))
        st.image(filtered_img, caption="é«˜é »æ¿¾æ³¢å¾Œçš„åœ–åƒ", use_container_width=True)

        # å°æ³¢è®Šæ›
        LL, LH, HL, HH = wavelet_transform(pil_img)
        st.image(LL, caption="å°æ³¢è®Šæ› LL éƒ¨åˆ†", use_container_width=True)
        st.image(HH, caption="å°æ³¢è®Šæ› HH éƒ¨åˆ†", use_container_width=True)

        face_img = extract_face(pil_img)
        if face_img:
            st.image(face_img, caption="åµæ¸¬åˆ°äººè‡‰", width=300)
            show_prediction(face_img, models)
        else:
            st.info("âš ï¸ æ²’åµæ¸¬åˆ°äººè‡‰ï¼Œä½¿ç”¨æ•´å¼µåœ–åƒé æ¸¬")
            show_prediction(pil_img, models)

with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆè™•ç†å‰å¹¾å¹€ï¼‰")
    uploaded_video = st.file_uploader("é¸æ“‡ä¸€æ®µå½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        st.info("ğŸ¬ æ­£åœ¨åˆ†æå½±ç‰‡...ï¼ˆå–å‰ 10 å¹€ï¼‰")
        cap = cv2.VideoCapture(video_path)
        frame_idx = 0
        shown = False
        max_frames = 10
        frame_confidences = []

        while cap.isOpened() and frame_idx < max_frames:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % 3 == 0:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_frame = Image.fromarray(rgb)

                # é«˜é »æ¿¾æ³¢è™•ç†
                filtered_frame = high_pass_filter(rgb)
                st.image(filtered_frame, caption=f"ç¬¬ {frame_idx} å¹€ é«˜é »æ¿¾æ³¢å¾Œ", width=300)

                # å°æ³¢è®Šæ›
                LL, LH, HL, HH = wavelet_transform(pil_frame)
                st.image(LL, caption=f"ç¬¬ {frame_idx} å¹€ å°æ³¢è®Šæ› LL éƒ¨åˆ†", width=300)

                face_img = extract_face(pil_frame)
                if face_img:
                    st.image(face_img, caption=f"ç¬¬ {frame_idx} å¹€äººè‡‰", width=300)
                    label, confidence = stacking_predict(models, face_img)
                    st.subheader(f"é æ¸¬çµæœï¼š**{label}**")
                    frame_confidences.append(confidence)
                    shown = True
                    if len(frame_confidences) == 10:
                        avg_confidence = np.mean(frame_confidences)
                        st.markdown(f"å½±ç‰‡ç¸½é«”ä¿¡å¿ƒåˆ†æ•¸ï¼š**{avg_confidence:.2f}**")
                        break
            frame_idx += 1

        cap.release()
        if not shown:
            st.warning("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°äººè‡‰ã€‚")
