import streamlit as st
import numpy as np
import cv2
import tempfile
import requests
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

# ä¸‹è¼‰æ¨¡å‹ï¼ˆåªæœƒä¸‹è¼‰ä¸€æ¬¡ï¼‰
@st.cache_resource
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_path = "deepfake_cnn_model.h5"
    if not os.path.exists(model_path):
        with st.spinner("ä¸‹è¼‰æ¨¡å‹ä¸­..."):
            r = requests.get(model_url)
            with open(model_path, "wb") as f:
                f.write(r.content)
    return load_model(model_path)

# ä½¿ç”¨ ResNet50 æ¨¡å‹é€²è¡Œé æ¸¬
def preprocess_for_both_models(image_path):
    img = image.load_img(image_path, target_size=(256, 256))  # èª¿æ•´å¤§å°
    img_array = image.img_to_array(img)
    
    # ResNet50 éœ€è¦ç‰¹åˆ¥çš„ preprocess_input
    resnet_input = preprocess_input(np.expand_dims(img_array, axis=0))
    
    # è‡ªè¨‚ CNN åªéœ€è¦æ­£è¦åŒ– (0~1)
    custom_input = np.expand_dims(img_array / 255.0, axis=0)
    
    return resnet_input, custom_input

# é€²è¡Œ ResNet50 é æ¸¬
def predict_with_both_models(image_path):
    resnet_input, custom_input = preprocess_for_both_models(image_path)
    
    # ResNet50 é æ¸¬
    resnet_prediction = resnet_classifier.predict(resnet_input)[0][0]
    resnet_label = "Deepfake" if resnet_prediction > 0.5 else "Real"
    
    # è‡ªè¨‚ CNN æ¨¡å‹é æ¸¬
    custom_prediction = custom_model.predict(custom_input)[0][0]
    custom_label = "Deepfake" if custom_prediction > 0.5 else "Real"
    
    return resnet_label, resnet_prediction, custom_label, custom_prediction

# äººè‡‰åµæ¸¬
def detect_face(img):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    img_array = np.array(img)
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)
    
    if len(faces) > 0:
        for (x, y, w, h) in faces:
            img_array = cv2.rectangle(img_array, (x, y), (x + w, y + h), (0, 255, 0), 2)
        face_img = Image.fromarray(img_array)
        return face_img
    return img

# é¡¯ç¤ºåœ–ç‰‡å’Œé æ¸¬çµæœ
def show_prediction(image_path):
    resnet_label, resnet_confidence, custom_label, custom_confidence = predict_with_both_models(image_path)
    
    # é¡¯ç¤ºåœ–ç‰‡
    img = image.load_img(image_path, target_size=(256, 256))
    st.image(img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)
    
    # é¡¯ç¤ºé æ¸¬çµæœ
    st.subheader(f"âœ… é æ¸¬çµæœï¼š")
    st.write(f"ResNet50 é æ¸¬ï¼š{resnet_label} ({resnet_confidence:.2%} ä¿¡å¿ƒåˆ†æ•¸)")
    st.write(f"Custom CNN é æ¸¬ï¼š{custom_label} ({custom_confidence:.2%} ä¿¡å¿ƒåˆ†æ•¸)")
    
    # é¡¯ç¤ºåµæ¸¬åˆ°çš„äººè‡‰
    face_img = detect_face(img)
    st.image(face_img, caption="åµæ¸¬åˆ°çš„äººè‡‰", use_container_width=True)

# ä¸»é é¢è¨­å®š
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–ç‰‡èˆ‡å½±ç‰‡åµæ¸¬å™¨")

model = download_model()

# ---------- åœ–ç‰‡åµæ¸¬ ----------
st.header("åœ–ç‰‡åµæ¸¬")
uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
if uploaded_image:
    pil_img = Image.open(uploaded_image).convert("RGB")
    show_prediction(uploaded_image)  # é¡¯ç¤ºåœ–ç‰‡èˆ‡é æ¸¬çµæœ

# ---------- å½±ç‰‡åµæ¸¬ ----------
st.header("å½±ç‰‡åµæ¸¬ï¼ˆæ¯ 10 å¹€æŠ½åœ–ï¼‰")
uploaded_video = st.file_uploader("ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
if uploaded_video:
    st.video(uploaded_video)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(uploaded_video.read())
        video_path = tmp.name

    st.info("ğŸ¬ æ“·å–å½±ç‰‡å¹€èˆ‡é€²è¡Œé æ¸¬ä¸­...")
    cap = cv2.VideoCapture(video_path)
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % 10 == 0:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(rgb_frame)
            st.image(pil_img, caption=f"ç¬¬ {frame_idx} å¹€", use_container_width=True)
            show_prediction(pil_img)  # é¡¯ç¤ºæ¯ä¸€å¹€çš„é æ¸¬çµæœ
        frame_idx += 1
    cap.release()
