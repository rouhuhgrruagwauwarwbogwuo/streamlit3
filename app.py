import streamlit as st
import numpy as np
import cv2
import os
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing import image
from mtcnn import MTCNN
import requests
from PIL import Image

st.set_page_config(page_title="Deepfake åµæ¸¬", layout="centered")

@st.cache_resource
def load_models():
    # ä¸‹è¼‰è‡ªè¨‚ CNN æ¨¡å‹
    cnn_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    cnn_path = "/tmp/deepfake_cnn_model.h5"
    if not os.path.exists(cnn_path):
        r = requests.get(cnn_url)
        with open(cnn_path, "wb") as f:
            f.write(r.content)
    custom_model = load_model(cnn_path)

    # ä¸‹è¼‰ ResNet50 åˆ†é¡å™¨ï¼ˆæ¥ Dense çš„é‚£å€‹ï¼‰
    resnet_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/resnet50_classifier.h5"
    resnet_path = "/tmp/resnet50_classifier.h5"
    if not os.path.exists(resnet_path):
        r = requests.get(resnet_url)
        with open(resnet_path, "wb") as f:
            f.write(r.content)
    resnet_model = load_model(resnet_path)

    return custom_model, resnet_model

custom_model, resnet_model = load_models()

# é è™•ç†åœ–ç‰‡
def preprocess_img_for_models(img_array):
    img_resized = cv2.resize(img_array, (256, 256))
    rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    norm = rgb / 255.0
    resnet_input = preprocess_input(np.expand_dims(rgb.astype('float32'), axis=0))
    custom_input = np.expand_dims(norm, axis=0)
    return resnet_input, custom_input

# äººè‡‰åµæ¸¬
def detect_face(img):
    detector = MTCNN()
    faces = detector.detect_faces(img)
    if faces:
        x, y, w, h = faces[0]["box"]
        return img[y:y+h, x:x+w]
    return img

# åœ–ç‰‡é æ¸¬
def predict_image(img_array):
    face = detect_face(img_array)
    resnet_input, custom_input = preprocess_img_for_models(face)
    resnet_pred = float(resnet_model.predict(resnet_input)[0][0])
    custom_pred = float(custom_model.predict(custom_input)[0][0])
    return resnet_pred, custom_pred

# é¡¯ç¤ºåœ–ç‰‡é æ¸¬çµæœ
def display_prediction(img, resnet_pred, custom_pred):
    st.image(img, caption="ä¸Šå‚³åœ–ç‰‡", use_container_width=True)
    st.markdown(f"ğŸ” **ResNet50 é æ¸¬**ï¼š{'Deepfake' if resnet_pred > 0.5 else 'Real'} ({resnet_pred:.2%})")
    st.markdown(f"ğŸ§  **è‡ªè¨‚ CNN é æ¸¬**ï¼š{'Deepfake' if custom_pred > 0.5 else 'Real'} ({custom_pred:.2%})")

# å½±ç‰‡é€å¹€è™•ç†èˆ‡é¡¯ç¤º
def process_video_file(video_bytes):
    with open("/tmp/temp_video.mp4", "wb") as f:
        f.write(video_bytes.read())
    cap = cv2.VideoCapture("/tmp/temp_video.mp4")
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or frame_idx > 100:  # é™åˆ¶æœ€å¤šé¡¯ç¤º 100 å¹€
            break
        if frame_idx % 10 == 0:
            resnet_pred, custom_pred = predict_image(frame)
            label = f"ResNet: {'DF' if resnet_pred > 0.5 else 'Real'} ({resnet_pred:.1%}), CNN: {'DF' if custom_pred > 0.5 else 'Real'} ({custom_pred:.1%})"
            frame = cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            st.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), caption=f"ç¬¬ {frame_idx} å¹€", use_column_width=True)
        frame_idx += 1
    cap.release()

# UI
st.title("ğŸ§  Deepfake åœ–ç‰‡èˆ‡å½±ç‰‡åµæ¸¬å™¨")

# åœ–ç‰‡ä¸Šå‚³
img_file = st.file_uploader("ğŸ“¸ ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
if img_file:
    img = Image.open(img_file).convert("RGB")
    img_array = np.array(img)
    resnet_pred, custom_pred = predict_image(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    display_prediction(img, resnet_pred, custom_pred)

# å½±ç‰‡ä¸Šå‚³
video_file = st.file_uploader("ğŸ¥ ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
if video_file:
    st.info("å½±ç‰‡åˆ†æä¸­ï¼Œè«‹ç¨å€™...")
    process_video_file(video_file)
