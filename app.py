import streamlit as st
import numpy as np
import os
import requests
from PIL import Image
import cv2
import tempfile
from keras.applications import ResNet50, EfficientNetB0, Xception
from keras.models import Sequential
from keras.layers import Dense
from keras.applications.resnet50 import preprocess_input as preprocess_resnet
from keras.applications.efficientnet import preprocess_input as preprocess_efficientnet
from keras.applications.xception import preprocess_input as preprocess_xception
from mtcnn import MTCNN

# åˆå§‹åŒ– MTCNN
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–åƒåµæ¸¬å™¨")
detector = MTCNN()

# è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_models():
    resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
    efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
    xception_model = Xception(weights='imagenet', include_top=False, pooling='avg', input_shape=(299, 299, 3))

    resnet_classifier = Sequential([resnet_model, Dense(1, activation='sigmoid')])
    efficientnet_classifier = Sequential([efficientnet_model, Dense(1, activation='sigmoid')])
    xception_classifier = Sequential([xception_model, Dense(1, activation='sigmoid')])

    return {
        'ResNet50': resnet_classifier,
        'EfficientNet': efficientnet_classifier,
        'Xception': xception_classifier
    }

# æå–äººè‡‰
@st.cache_data(show_spinner=False)
def extract_face(pil_img):
    img_array = np.array(pil_img)
    faces = detector.detect_faces(img_array)
    if faces:
        x, y, w, h = faces[0]['box']
        face = img_array[y:y+h, x:x+w]
        return Image.fromarray(face)
    return None

# é è™•ç†åœ–åƒ
def preprocess_image(img, model_name):
    if model_name == 'Xception':
        img = img.resize((299, 299))
        img_array = np.array(img).astype(np.float32)
        return preprocess_xception(img_array)
    else:
        img = img.resize((224, 224))
        img_array = np.array(img).astype(np.float32)
        if model_name == 'ResNet50':
            return preprocess_resnet(img_array)
        elif model_name == 'EfficientNet':
            return preprocess_efficientnet(img_array)
    return img_array

# å–®æ¨¡å‹é æ¸¬
def predict_model(models, img):
    predictions = []
    for name, model in models.items():
        input_data = preprocess_image(img, name)
        prediction = model.predict(np.expand_dims(input_data, axis=0), verbose=0)
        predictions.append(prediction[0][0])
    return predictions

# é›†æˆé æ¸¬ï¼ˆç°¡å–®å¹³å‡ï¼‰
def stacking_predict(models, img):
    preds = predict_model(models, img)
    avg = np.mean(preds)
    return "Deepfake" if avg > 0.5 else "Real"

# é¡¯ç¤ºé æ¸¬çµæœ
def show_prediction(img, models):
    label = stacking_predict(models, img)
    st.image(img, caption="è¼¸å…¥åœ–åƒ", use_container_width=True)
    st.subheader(f"é æ¸¬çµæœï¼š**{label}**")

# UI Tab
models = load_models()
tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–åƒåµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

with tab1:
    st.header("ä¸Šå‚³åœ–åƒé€²è¡Œ Deepfake åµæ¸¬")
    uploaded_image = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–åƒ", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–åƒ", use_container_width=True)

        face_img = extract_face(pil_img)
        if face_img:
            st.image(face_img, caption="åµæ¸¬åˆ°äººè‡‰", width=300)
            show_prediction(face_img, models)
        else:
            st.info("âš ï¸ æ²’åµæ¸¬åˆ°äººè‡‰ï¼Œä½¿ç”¨æ•´å¼µåœ–åƒé æ¸¬")
            show_prediction(pil_img, models)

with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆè™•ç†å‰å¹¾å¹€ï¼‰")
    uploaded_video = st.file_uploader("é¸æ“‡ä¸€æ®µå½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        st.info("ğŸ¬ æ­£åœ¨åˆ†æå½±ç‰‡...ï¼ˆå–å‰ 10 å¹€ï¼‰")
        cap = cv2.VideoCapture(video_path)
        frame_idx = 0
        shown = False
        max_frames = 10

        while cap.isOpened() and frame_idx < max_frames:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % 3 == 0:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_frame = Image.fromarray(rgb)
                face_img = extract_face(pil_frame)
                if face_img:
                    st.image(face_img, caption=f"ç¬¬ {frame_idx} å¹€äººè‡‰", width=300)
                    label = stacking_predict(models, face_img)
                    st.subheader(f"é æ¸¬çµæœï¼š**{label}**")
                    shown = True
                    break
            frame_idx += 1

        cap.release()
        if not shown:
            st.warning("âš ï¸ æ²’æœ‰åµæ¸¬åˆ°äººè‡‰ã€‚")
