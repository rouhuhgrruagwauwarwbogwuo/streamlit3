import os
import numpy as np
import cv2
import tempfile
import requests
import h5py
import streamlit as st
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.layers import Dense
from mtcnn.mtcnn import MTCNN  # âœ… ä½¿ç”¨ MTCNN

# Hugging Face æ¨¡å‹ä¸‹è¼‰ç¶²å€
MODEL_URL = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"

@st.cache_resource
def download_model():
    model_path = os.path.join(tempfile.gettempdir(), "deepfake_cnn_model.h5")
    if not os.path.exists(model_path):
        response = requests.get(MODEL_URL)
        if response.status_code == 200:
            with open(model_path, "wb") as f:
                f.write(response.content)
        else:
            st.error("âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—ã€‚")
            raise Exception("æ¨¡å‹ä¸‹è¼‰å¤±æ•—ã€‚")
    try:
        with h5py.File(model_path, 'r') as f:
            pass
    except OSError:
        st.error("âŒ æ¨¡å‹æª”æ¡ˆç„¡æ³•è®€å–ã€‚")
        raise
    return load_model(model_path)

# è¼‰å…¥æ¨¡å‹
try:
    custom_model = download_model()
except Exception as e:
    st.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    st.stop()

efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))
efficientnet_classifier = Sequential([
    efficientnet_model,
    Dense(1, activation='sigmoid')
])
efficientnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

detector = MTCNN()  # âœ… åˆå§‹åŒ– MTCNN åµæ¸¬å™¨

# âœ… MTCNN åµæ¸¬äººè‡‰ä¸¦æ¡†ä½
def draw_face_box(img, label, confidence):
    results = detector.detect_faces(img)
    color = (0, 0, 255) if label == "Deepfake" else (0, 255, 0)
    for result in results:
        x, y, w, h = result['box']
        cv2.rectangle(img, (x, y), (x + w, y + h), color, 3)
        text = f"{label} ({confidence:.2%})"
        cv2.putText(img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    return img

def process_image(file_bytes):
    try:
        # ç›´æ¥è§£ç¢¼ä¸¦é¡¯ç¤ºåŸå§‹åœ–ç‰‡
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        # é¡¯ç¤ºåŸå§‹åœ–ç‰‡
        st.image(img, caption="ä¸Šå‚³çš„åŸå§‹åœ–ç‰‡", use_container_width=True)

        # é€²è¡Œé æ¸¬
        img_resized = cv2.resize(img, (256, 256))
        eff_input = preprocess_input(np.expand_dims(img_resized, axis=0))
        custom_input = np.expand_dims(img_resized / 255.0, axis=0)
        
        # é æ¸¬
        eff_pred = efficientnet_classifier.predict(eff_input)[0][0]
        custom_pred = custom_model.predict(custom_input)[0][0]
        combined_pred = (eff_pred + custom_pred) / 2
        label = "Deepfake" if combined_pred > 0.5 else "Real"
        confidence = combined_pred if combined_pred > 0.5 else 1 - combined_pred

        # é¡¯ç¤ºé æ¸¬çµæœ
        boxed_img = draw_face_box(img, label, confidence)
        st.image(boxed_img, caption=f"é æ¸¬çµæœï¼š{label} ({confidence:.2%})", use_container_width=True)
        
        plot_confidence(eff_pred, custom_pred, combined_pred)
    except Exception as e:
        st.error(f"âŒ åœ–ç‰‡è™•ç†éŒ¯èª¤: {e}")

# ğŸ”¹ Streamlit UI
st.title("ğŸ•µï¸ Deepfake åµæ¸¬ App")
option = st.radio("è«‹é¸æ“‡æª”æ¡ˆé¡å‹ï¼š", ("åœ–ç‰‡", "å½±ç‰‡"))

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³æª”æ¡ˆ", type=["jpg", "jpeg", "png", "mp4", "mov"])

if uploaded_file is not None:
    try:
        if option == "åœ–ç‰‡" and uploaded_file.type.startswith("image"):
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            process_image(file_bytes)
        elif option == "å½±ç‰‡" and uploaded_file.type.startswith("video"):
            st.markdown("### è™•ç†å½±ç‰‡ä¸­...")
            processed_video_path = process_video_and_generate_result(uploaded_file)
            if processed_video_path:
                st.video(processed_video_path)
        else:
            st.warning("è«‹ç¢ºèªä¸Šå‚³çš„æª”æ¡ˆé¡å‹èˆ‡é¸æ“‡ä¸€è‡´ã€‚")
    except Exception as e:
        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
