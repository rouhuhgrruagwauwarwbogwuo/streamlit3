import streamlit as st
import numpy as np
import cv2
from PIL import Image
import tensorflow as tf
from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from keras.preprocessing import image as keras_image
from mtcnn import MTCNN

# åˆå§‹åŒ–æ¨¡å‹
resnet_model = ResNet50(weights='imagenet')
detector = MTCNN()

st.title("ğŸ” Deepfake åµæ¸¬ï¼ˆResNet50ï¼‰")

# ä¸­å¿ƒè£åˆ‡ä¸¦ resize
def center_crop_and_resize(img, target_size=(224, 224)):
    width, height = img.size
    new_short = min(width, height)
    left = (width - new_short) // 2
    top = (height - new_short) // 2
    right = left + new_short
    bottom = top + new_short
    img_cropped = img.crop((left, top, right, bottom))
    return img_cropped.resize(target_size)

# CLAHE å¢å¼·åœ–åƒç´°ç¯€
def enhance_image(img):
    img_cv = np.array(img)
    img_yuv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2YUV)
    img_yuv[:, :, 0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img_yuv[:, :, 0])
    img_eq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)
    return Image.fromarray(img_eq)

# åµæ¸¬ä¸¦æ“·å–äººè‡‰ï¼ˆå›å‚³ç¬¬ä¸€å¼µè‡‰ï¼‰
def extract_face(pil_img):
    img_np = np.array(pil_img)
    faces = detector.detect_faces(img_np)
    if faces:
        x, y, w, h = faces[0]['box']
        face = img_np[y:y+h, x:x+w]
        return Image.fromarray(face)
    return pil_img  # è‹¥ç„¡åµæ¸¬åˆ°äººè‡‰å‰‡å‚³å›åŸåœ–

# ResNet é æ¸¬
def predict_with_resnet(img):
    img_array = keras_image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    preds = resnet_model.predict(img_array)
    decoded = decode_predictions(preds, top=1)[0][0]
    label = decoded[1]
    confidence = float(decoded[2])
    return label, confidence

# UI
uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])

if uploaded_file:
    pil_img = Image.open(uploaded_file).convert("RGB")
    st.image(pil_img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)

    face_img = extract_face(pil_img)
    st.image(face_img, caption="æ“·å–äººè‡‰", use_container_width=True)

    # ä¸­å¿ƒè£åˆ‡èˆ‡åœ–åƒå¢å¼·
    face_img = center_crop_and_resize(face_img, (224, 224))
    face_img = enhance_image(face_img)

    # é æ¸¬
    label, confidence = predict_with_resnet(face_img)

    st.subheader("ğŸ” é æ¸¬çµæœ")
    st.write(f"**é¡åˆ¥**ï¼š{label}")
    st.write(f"**ä¿¡å¿ƒåˆ†æ•¸**ï¼š{confidence:.2f}")
