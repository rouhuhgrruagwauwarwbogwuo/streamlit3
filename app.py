import streamlit as st
import numpy as np
import cv2
import requests
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# ---------- æ¨¡å‹ä¸‹è¼‰èˆ‡è¼‰å…¥ ----------
MODEL_PATH = "deepfake_cnn_model.h5"
MODEL_URL = "https://huggingface.co/wuwuwu123123/deepfake3/resolve/main/deepfake_cnn_model.h5"

@st.cache_resource
def download_and_load_model():
    if not os.path.exists(MODEL_PATH):
        with requests.get(MODEL_URL, stream=True) as r:
            r.raise_for_status()
            with open(MODEL_PATH, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
    return load_model(MODEL_PATH)

model = download_and_load_model()

# ---------- åœ–ç‰‡é è™•ç† ----------
def preprocess_image(uploaded_file, target_size=(256, 256)):
    try:
        img = Image.open(uploaded_file).convert("RGB").resize(target_size)
        img_array = np.array(img)

        # ä¸­å€¼æ¿¾æ³¢å»å™ª
        img_array = cv2.medianBlur(img_array.astype('uint8'), 3)

        # CLAHE å¢å¼·å°æ¯”åº¦
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        img_gray = clahe.apply(img_gray)
        img_array = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)

        # æ­£è¦åŒ–
        img_array = img_array / 255.0
        return np.expand_dims(img_array, axis=0)
    except Exception as e:
        st.error(f"é è™•ç†éŒ¯èª¤ï¼š{e}")
        return None

# ---------- é æ¸¬çµæœ ----------
def predict_image(uploaded_file):
    img_array = preprocess_image(uploaded_file)

    if img_array is not None:
        prediction = model.predict(img_array)[0][0]
        label = "Deepfake" if prediction > 0.5 else "Real"
        confidence = prediction if prediction > 0.5 else 1 - prediction
        return label, confidence
    else:
        return None, None

# ---------- é¡¯ç¤ºåœ–ç‰‡é æ¸¬ ----------
def show_image_prediction(uploaded_file):
    label, confidence = predict_image(uploaded_file)
    
    if label is not None:
        st.image(uploaded_file, caption="ä¸Šå‚³çš„åœ–ç‰‡", use_column_width=True)
        st.markdown(f"### ğŸ” é æ¸¬çµæœï¼š**{label}**")
        st.markdown(f"### ğŸ“Š ä¿¡å¿ƒåˆ†æ•¸ï¼š**{confidence:.2%}**")
    else:
        st.error("ç„¡æ³•é¡¯ç¤ºé æ¸¬çµæœ")

# ---------- å½±ç‰‡é æ¸¬ ----------
def predict_video(video_file):
    cap = cv2.VideoCapture(video_file)
    frame_interval = 5
    frame_count = 0
    frame_buffer = []
    predictions = []

    while cap.isOpened():
        ret, frame = cap.read()

        if not ret:
            break  # å½±ç‰‡è®€å–çµæŸ

        if frame_count % frame_interval == 0:
            # åµæ¸¬æ¯å¹€ä¸­çš„äººè‡‰
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

            for (x, y, w, h) in faces:
                face = frame[y:y + h, x:x + w]
                face_resized = cv2.resize(face, (256, 256))
                face_array = np.expand_dims(face_resized / 255.0, axis=0)
                prediction = model.predict(face_array)[0][0]
                predictions.append(prediction)

        frame_count += 1

    cap.release()

    if predictions:
        avg_prediction = np.mean(predictions)
        label = "Deepfake" if avg_prediction > 0.5 else "Real"
        confidence = avg_prediction if avg_prediction > 0.5 else 1 - avg_prediction
        return label, confidence
    else:
        return None, None

# ---------- é¡¯ç¤ºå½±ç‰‡é æ¸¬ ----------
def show_video_prediction(uploaded_video):
    label, confidence = predict_video(uploaded_video)
    
    if label is not None:
        st.video(uploaded_video)
        st.markdown(f"### ğŸ” é æ¸¬çµæœï¼š**{label}**")
        st.markdown(f"### ğŸ“Š ä¿¡å¿ƒåˆ†æ•¸ï¼š**{confidence:.2%}**")
    else:
        st.error("ç„¡æ³•é¡¯ç¤ºé æ¸¬çµæœ")

# ---------- Streamlit UI ----------
st.title("ğŸ§  Deepfake åµæ¸¬ App")
st.write("è«‹é¸æ“‡åœ–ç‰‡æˆ–å½±ç‰‡ï¼Œç³»çµ±å°‡è‡ªå‹•åˆ¤æ–·æ˜¯å¦ç‚º Deepfakeã€‚")

choice = st.radio("é¸æ“‡æª”æ¡ˆé¡å‹", ("åœ–ç‰‡", "å½±ç‰‡"))

if choice == "åœ–ç‰‡":
    uploaded_file = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        show_image_prediction(uploaded_file)

elif choice == "å½±ç‰‡":
    uploaded_video = st.file_uploader("ä¸Šå‚³å½±ç‰‡", type=["mp4", "avi", "mov"])

    if uploaded_video is not None:
        show_video_prediction(uploaded_video)
