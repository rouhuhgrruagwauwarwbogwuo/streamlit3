import streamlit as st
import numpy as np
import cv2
import tempfile
import requests
import os
from PIL import Image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# ä¸‹è¼‰æ¨¡å‹ï¼ˆåªæœƒä¸‹è¼‰ä¸€æ¬¡ï¼‰
@st.cache_resource
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_path = "deepfake_cnn_model.h5"
    if not os.path.exists(model_path):
        with st.spinner("ä¸‹è¼‰æ¨¡å‹ä¸­..."):
            r = requests.get(model_url)
            with open(model_path, "wb") as f:
                f.write(r.content)
    return load_model(model_path)

# åœ–åƒé è™•ç†ï¼ˆç°¡åŒ–ï¼‰
def preprocess_pil_image(pil_img, target_size=(256, 256)):
    img = pil_img.resize(target_size)
    img_array = image.img_to_array(img) / 255.0
    return np.expand_dims(img_array, axis=0)

# å–®å¼µåœ–ç‰‡é æ¸¬
def predict(model, pil_img):
    img_array = preprocess_pil_image(pil_img)
    pred = model.predict(img_array)[0][0]
    label = "Deepfake" if pred > 0.5 else "Real"
    confidence = pred if pred > 0.5 else 1 - pred
    return label, confidence

# å¾å½±ç‰‡æ“·å–å¹€ï¼ˆæ¯ 10 å¹€ï¼‰
def extract_frames(video_path, interval=10):
    cap = cv2.VideoCapture(video_path)
    frames = []
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % interval == 0:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(rgb_frame)
            frames.append((frame_idx, pil_img))
        frame_idx += 1
    cap.release()
    return frames

# å¹€åœ–é æ¸¬
def predict_frames(model, frames):
    results = []
    for idx, frame in frames:
        label, confidence = predict(model, frame)
        results.append((idx, frame, label, confidence))
    return results

# ==== Streamlit App ä¸»é«” ====
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–ç‰‡èˆ‡å½±ç‰‡åµæ¸¬å™¨")

model = download_model()

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–ç‰‡åµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

# ---------- åœ–ç‰‡ ----------
with tab1:
    st.header("åœ–ç‰‡åµæ¸¬")
    uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–ç‰‡", use_column_width=True)
        label, confidence = predict(model, pil_img)
        st.subheader(f"âœ… é æ¸¬çµæœï¼š{label} ({confidence:.2%} ä¿¡å¿ƒåˆ†æ•¸)")

# ---------- å½±ç‰‡ ----------
with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆæ¯ 10 å¹€æŠ½åœ–ï¼‰")
    uploaded_video = st.file_uploader("ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        st.info("ğŸ¬ æ“·å–å½±ç‰‡å¹€èˆ‡é€²è¡Œé æ¸¬ä¸­...")
        frames = extract_frames(video_path, interval=10)
        results = predict_frames(model, frames)

        for idx, frame, label, confidence in results:
            st.image(frame, caption=f"ç¬¬ {idx} å¹€ - {label} ({confidence:.2%})", use_column_width=True)
