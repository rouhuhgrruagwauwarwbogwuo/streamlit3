import numpy as np
import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from PIL import Image, ImageEnhance, ImageFilter
import tempfile
import os
import requests
from mtcnn import MTCNN

# ğŸ”½ ä¸‹è¼‰è‡ªè¨‚ CNN æ¨¡å‹ï¼ˆå¾ Hugging Faceï¼‰
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_filename = "deepfake_cnn_model.h5"
    
    if not os.path.exists(model_filename):
        response = requests.get(model_url)
        if response.status_code == 200:
            with open(model_filename, "wb") as f:
                f.write(response.content)
            print("æ¨¡å‹æª”æ¡ˆå·²æˆåŠŸä¸‹è¼‰ï¼")
        else:
            print(f"ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")
            return None
    return model_filename

# ğŸ”¹ è¼‰å…¥ ResNet50 æ¨¡å‹
try:
    resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
    resnet_classifier = Sequential([
        resnet_model,
        Dense(1, activation='sigmoid')  
    ])
    resnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    print("ResNet50 æ¨¡å‹å·²æˆåŠŸè¼‰å…¥")
except Exception as e:
    print(f"è¼‰å…¥ ResNet50 æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    resnet_classifier = None

# ğŸ”¹ è¼‰å…¥è‡ªè¨‚ CNN æ¨¡å‹
model_path = download_model()
if model_path:
    try:
        custom_model = load_model(model_path)
        print("è‡ªè¨‚ CNN æ¨¡å‹å·²æˆåŠŸè¼‰å…¥")
    except Exception as e:
        print(f"è¼‰å…¥è‡ªè¨‚ CNN æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        custom_model = None
else:
    custom_model = None

# ğŸ”¹ åˆå§‹åŒ– MTCNN äººè‡‰æª¢æ¸¬å™¨
detector = MTCNN()

# ğŸ”¹ æ“·å–åœ–ç‰‡ä¸­çš„äººè‡‰
def extract_face(pil_img):
    img_array = np.array(pil_img)
    faces = detector.detect_faces(img_array)

    if len(faces) > 0:
        x, y, width, height = faces[0]['box']
        face = img_array[y:y+height, x:x+width]
        face_pil = Image.fromarray(face)
        return face_pil
    else:
        return None

# ğŸ”¹ ä¸­å¿ƒè£åˆ‡å‡½æ•¸
def center_crop(img, target_size=(224, 224)):
    width, height = img.size
    new_width, new_height = target_size
    left = (width - new_width) // 2
    top = (height - new_height) // 2
    right = left + new_width
    bottom = top + new_height
    return img.crop((left, top, right, bottom))

# ğŸ”¹ CLAHE é è™•ç†
def apply_clahe(image):
    enhancer = ImageEnhance.Contrast(image)
    image_clahe = enhancer.enhance(2)  # å¢åŠ å°æ¯”åº¦
    return image_clahe

# ğŸ”¹ é »åŸŸåˆ†æ (FFT)
def apply_fft(image):
    img_gray = image.convert('L')  # è½‰æ›ç‚ºç°éšåœ–åƒ
    img_array = np.array(img_gray)

    # è¨ˆç®—å‚…ç«‹è‘‰è®Šæ›
    f = np.fft.fft2(img_array)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = np.log(np.abs(fshift) + 1)

    # è½‰æ›å›åœ–åƒ
    magnitude_spectrum_img = Image.fromarray(np.uint8(magnitude_spectrum * 255 / magnitude_spectrum.max()))
    return magnitude_spectrum_img

# ğŸ”¹ åœ–ç‰‡é è™•ç†ï¼ˆåŒ…æ‹¬ CLAHE å’Œ FFTï¼‰
def preprocess_for_both_models(img):
    img = img.resize((256, 256), Image.Resampling.LANCZOS)
    img = apply_clahe(img)  # CLAHE è™•ç†
    img = apply_fft(img)    # é »åŸŸè™•ç†
    img = center_crop(img, (224, 224))  # ä¸­å¿ƒè£åˆ‡
    img_array = np.array(img)
    img_array = img_array.astype(np.float32) / 255.0

    # æ“´å±•ç¶­åº¦ä»¥ç¬¦åˆæ¨¡å‹è¼¸å…¥è¦æ±‚ï¼š (batch_size, height, width, channels)
    resnet_input = np.expand_dims(img_array, axis=0)
    custom_input = np.expand_dims(img_array, axis=0)

    return resnet_input, custom_input

# ğŸ”¹ æ¨¡å‹é æ¸¬
def predict_with_both_models(img, only_resnet=False):
    resnet_input, custom_input = preprocess_for_both_models(img)
    resnet_prediction = resnet_classifier.predict(resnet_input)[0][0]
    resnet_label = "Deepfake" if resnet_prediction > 0.5 else "Real"

    if only_resnet or not custom_model:
        return resnet_label, resnet_prediction, "", 0.0
    else:
        # ç¢ºä¿è¼¸å…¥çš„æ•¸æ“šèˆ‡æ¨¡å‹é æœŸçš„ç¶­åº¦ä¸€è‡´
        custom_prediction = custom_model.predict(custom_input)[0][0]
        custom_label = "Deepfake" if custom_prediction > 0.5 else "Real"
        return resnet_label, resnet_prediction, custom_label, custom_prediction

# ğŸ”¹ é¡¯ç¤ºé æ¸¬çµæœ
def show_prediction(img, only_resnet=False):
    resnet_label, resnet_confidence, custom_label, custom_confidence = predict_with_both_models(img, only_resnet)

    st.image(img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)
    st.image(img, caption="åµæ¸¬åˆ°çš„äººè‡‰", use_container_width=False, width=300)
    st.subheader(f"ResNet50: {resnet_label} ({resnet_confidence:.2%})")
    if not only_resnet:
        st.subheader(f"Custom CNN: {custom_label} ({custom_confidence:.2%})")

# ğŸ”¹ Streamlit ä¸»é é¢
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–ç‰‡åµæ¸¬å™¨")

# ---------- åœ–ç‰‡ ---------- 
st.header("åœ–ç‰‡åµæ¸¬")
uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
if uploaded_image:
    pil_img = Image.open(uploaded_image).convert("RGB")
    st.image(pil_img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)

    face_img = extract_face(pil_img)
    if face_img:
        st.image(face_img, caption="åµæ¸¬åˆ°çš„äººè‡‰", use_container_width=False, width=300)
        show_prediction(face_img, only_resnet=True)
    else:
        st.write("æœªåµæ¸¬åˆ°äººè‡‰ï¼Œä½¿ç”¨æ•´é«”åœ–ç‰‡é€²è¡Œé æ¸¬")
        show_prediction(pil_img, only_resnet=True)
